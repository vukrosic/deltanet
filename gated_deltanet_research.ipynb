{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gated DeltaNet Research Notebook\n",
    "\n",
    "This notebook is for researching Gated DeltaNet on Google Colab.\n",
    "\n",
    "**Paper**: [Gated Delta Networks: Improving Mamba2 with Delta Rule](https://arxiv.org/abs/2412.06464)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/sustcsonglin/flash-linear-attention.git\n",
    "%cd flash-linear-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -e .\n",
    "!pip install transformers einops torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Gated DeltaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from fla.layers import GatedDeltaNet\n",
    "from fla.models import GatedDeltaNetConfig, GatedDeltaNetForCausalLM, GatedDeltaNetModel\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Layer Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Gated DeltaNet layer\n",
    "layer = GatedDeltaNet(\n",
    "    hidden_size=512,\n",
    "    expand_v=2.0,\n",
    "    head_dim=64,\n",
    "    num_heads=8,\n",
    "    mode='chunk',\n",
    "    use_gate=True,\n",
    "    use_short_conv=True,\n",
    ")\n",
    "\n",
    "# Test with random input\n",
    "batch_size = 2\n",
    "seq_len = 128\n",
    "hidden_size = 512\n",
    "\n",
    "x = torch.randn(batch_size, seq_len, hidden_size)\n",
    "output, _, _ = layer(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small Gated DeltaNet model\n",
    "config = GatedDeltaNetConfig(\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=12,\n",
    "    num_heads=12,\n",
    "    head_dim=64,\n",
    "    vocab_size=50257,\n",
    ")\n",
    "\n",
    "model = GatedDeltaNetForCausalLM(config)\n",
    "print(f\"Model created with {sum(p.numel() for p in model.parameters())/1e6:.2f}M parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Forward Pass Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass\n",
    "input_ids = torch.randint(0, config.vocab_size, (2, 64))\n",
    "outputs = model(input_ids)\n",
    "\n",
    "print(f\"Input IDs shape: {input_ids.shape}\")\n",
    "print(f\"Logits shape: {outputs.logits.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Research Experiments\n",
    "\n",
    "Add your research experiments below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your experiments here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Architecture Components\n",
    "\n",
    "### Gated DeltaNet Layer Parameters:\n",
    "\n",
    "- **hidden_size**: Hidden dimension\n",
    "- **expand_v**: Value dimension expansion ratio (default: 2.0)\n",
    "- **head_dim**: Dimension per head\n",
    "- **num_heads**: Number of attention heads\n",
    "- **num_v_heads**: Number of value heads (GVA if > num_heads)\n",
    "- **mode**: Kernel mode ('chunk' or 'fused_recurrent')\n",
    "- **use_beta**: Use beta parameter\n",
    "- **use_gate**: Use output gating\n",
    "- **use_short_conv**: Use short convolutions\n",
    "- **allow_neg_eigval**: Allow negative eigenvalues\n",
    "- **conv_size**: Convolution kernel size\n",
    "\n",
    "### Key Operations:\n",
    "- `chunk_gated_delta_rule`: Chunk-based implementation (training)\n",
    "- `fused_recurrent_gated_delta_rule`: Fused recurrent (inference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
